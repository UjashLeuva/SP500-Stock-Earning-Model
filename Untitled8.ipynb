{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"af40190ac3274d36aee4a7e801e865c7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_json(year, month, api):\n",
    "    \"Download news for a particular year and month and save as a json file\"\n",
    "    \n",
    "    url = \"http://api.nytimes.com/svc/archive/v1/{}/{}.json?api-key={}\"\n",
    "    url = url.format(year, month, api)\n",
    "    \n",
    "    file_str = 'data/' + str(year) + '-' + '{:02}'.format(month) + '.json'\n",
    "\n",
    "    items = requests.get(url)\n",
    "    \n",
    "    try:\n",
    "        data = items.json()\n",
    "\n",
    "        with open(file_str, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return \"Finished downloading {}/{}\".format(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finished downloading 2018/2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_json(2018, 2, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment to download it since 2013 to present\n",
    "for i in range(2013, 2018):\n",
    "    for j in range(1, 13):\n",
    "        download_json(i, j, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(year, month):\n",
    "    \"Save as pandas dataframe\"\n",
    "    file_str = 'data/' + str(year) + '-' + '{:02}'.format(month) + '.json'\n",
    "    with open(file_str) as data_file:    \n",
    "        NYTimes_data = json.load(data_file)\n",
    "    \n",
    "    date_list = []\n",
    "    df = pd.DataFrame()  \n",
    "    df['News'] = None\n",
    "    \n",
    "\n",
    "    for i in range(len(NYTimes_data[\"response\"][\"docs\"][:])):\n",
    "        if NYTimes_data[\"response\"][\"docs\"][i][\"pub_date\"][:10] not in df.index:\n",
    "            df.ix[NYTimes_data[\"response\"][\"docs\"][i][\"pub_date\"][:10]] = NYTimes_data[\"response\"][\"docs\"][:][i]['headline']['main']\n",
    "        else:\n",
    "            df.ix[NYTimes_data[\"response\"][\"docs\"][i][\"pub_date\"][:10]] = df.ix[NYTimes_data[\"response\"][\"docs\"][i][\"pub_date\"][:10]].values + NYTimes_data[\"response\"][\"docs\"][:][i]['headline']['main']\n",
    "    \n",
    "    df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/2015-05.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4db6c3818b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-8f314604ddb4>\u001b[0m in \u001b[0;36mopen_json\u001b[0;34m(year, month)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"Save as pandas dataframe\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{:02}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mNYTimes_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/2015-05.json'"
     ]
    }
   ],
   "source": [
    "df = open_json(2015,5)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stocknews'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0da683dc4b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstocknews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStocknewsItem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLivemintSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stocknews'"
     ]
    }
   ],
   "source": [
    "# This package will contain the spiders of your Scrapy project\n",
    "#\n",
    "# Please refer to the documentation for information on how to create and manage\n",
    "# your spiders.\n",
    "\"\"\"\n",
    "Created on Mon Nov 14 23:16:56 2016\n",
    "@author: ZNevzz\n",
    "\"\"\"\n",
    "\n",
    "import scrapy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from stocknews.items import StocknewsItem\n",
    "\n",
    "class LivemintSpider(scrapy.Spider):\n",
    "    \n",
    "    #spider name\n",
    "    name = \"livemint_spider\"\n",
    "    #domains\n",
    "    allowed_domains = [\"livemint.com\"]\n",
    "    #urls\n",
    "    start_urls = []\n",
    "    file_name = 'livemint_data_3.csv'\n",
    "    df = pd.read_csv(file_name,encoding='iso-8859-1')\n",
    "    start_urls = df['href'].tolist()\n",
    "    \n",
    "    ## end\n",
    "\n",
    "\n",
    "    def parse(self, response):\n",
    "    \n",
    "        path = \"/html/body/div[@id='o-wrapper']/div[@class='wrapper']/section[@class='left-col']/div[@id='div_storyContent']/div[@class='story-content']/p\"\n",
    "        body = response.selector.xpath(path).extract()\n",
    "        result=\"\"\n",
    "        for i in body:\n",
    "            temp = re.sub(\"<p>\", \"\", i)\n",
    "            temp = re.sub(\"</p>\",\"\",temp)\n",
    "            temp = re.sub(\"<i>The writer does not own shares in the above-mentioned companies.</i>\",\"\",temp)\n",
    "            result=result+temp\n",
    "        \n",
    "        result = result.strip()\n",
    "        return {'href':response.url,'body':result}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_articles():\n",
    "    data = DataFrame(columns=('Date', 'Day #', 'Title', 'Content'))\n",
    "    date = datetime.date(2016, 11, 7)\n",
    "    for counter in range(1, 59):\n",
    "        date = date + datetime.timedelta(days=1)\n",
    "        url = \"http://www.thehindu.com/template/widget_jsp/code_widget/archive/archiveWebDayRest.jsp?d=\" + date.isoformat()\n",
    "        soup = BeautifulSoup(requests.get(url).text)\n",
    "        num = 0\n",
    "        for link in soup.findAll('a'):\n",
    "            lt = link.text.encode('utf-8').strip().lower()\n",
    "            if ('demonetisation' in lt) or ('demonetization' in lt) or ('1000' in lt) or ('currency' in lt):\n",
    "                try:\n",
    "                    article_soup = BeautifulSoup(requests.get(link.get('href')).text)\n",
    "                    paragraphs = article_soup.find_all('p')\n",
    "                    text = \" \".join([ paragraph.text.encode('utf-8').strip() for paragraph in paragraphs])\n",
    "                    title = link.text.encode('utf-8').strip()\n",
    "                    article_data = DataFrame([[date, counter, title, text]], columns=('Date', 'Day #', 'Title', 'Content'))\n",
    "                    data = data.append(article_data, ignore_index = True)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        data.to_csv('data.csv', encoding='utf-8')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e0dd21b26f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('data_final.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
